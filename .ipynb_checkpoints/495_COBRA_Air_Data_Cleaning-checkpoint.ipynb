{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set the working directory. This code will be changed based on the relative location of the data files \n",
    "# on the local drive of the computer executing the command. \n",
    "os.chdir('C:\\\\Users\\\\belincoln\\\\Documents\\\\! CBP\\\\!User Fees\\\\!! Goal 1 Dashboards')\n",
    "\n",
    "# Works well for Jupyter Notebooks, can be configured in Spyder using file explorer. \n",
    "collections = pd.read_excel(os.path.join('Source Emails & Source Files','Files','Collections',\n",
    "                                         'COBRA_Air','Collections cc495 - FY13 - FY18.xls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin Data Cleaning\n",
    "# delete columns and rows that contain only na\n",
    "collections = collections.dropna(axis=0, how = 'all')\n",
    "collections = collections.dropna(axis=1, how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the first two rows and only keep the Period Column and Collection Columns\n",
    "collections = collections.iloc[2:,[1,-1,-3,-4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make first row column headers\n",
    "collections.columns = collections.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all columns have a name! Rename first column 'Period'\n",
    "# Delete first two rows\n",
    "collections.columns.values[0] = 'Period'\n",
    "\n",
    "collections = collections.iloc[2:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows that contain sums for each company (don't want to double count collections)\n",
    "# Also delete additional NaNs\n",
    "collections = collections.dropna(axis = 0, subset = ['Period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum Interest, Penalty, and Principal Collection Amounts\n",
    "collections['Collections'] = collections[['Applied Penalty Amount', 'Applied Interest Amount',\n",
    "       'Applied Principal Amount']].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tilda from index (unclear why it exists in the first place)\n",
    "collections['Period'] = collections['Period'].str.rstrip('~')\n",
    "# remove extra space from index\n",
    "collections['Period'] = collections['Period'].str.rstrip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups Collections based on Collection Period, across all companies\n",
    "collections = collections.groupby(collections['Period']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove audit payments\n",
    "collections= collections[~collections.index.str.contains(\"\\*\")]\n",
    "\n",
    "# Add an additional column that shows remittance period (independent of year)\n",
    "collections['Remittance Period'] = collections.index.str.split('20').str[0]\n",
    "\n",
    "\n",
    "# Create Calendar Year Column\n",
    "collections['Calendar Year'] = collections.index.str.split(')').str[1]\n",
    "# Turn Years into integers\n",
    "collections['Calendar Year'] = collections['Calendar Year'].astype(int)\n",
    "\n",
    "# Filter on years not a part of analysis\n",
    "years = [2012,2013,2014,2015,2016,2017,2018]\n",
    "collections = collections[collections['Calendar Year'].isin(years)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove collection data for which we don't have workload data\n",
    "searchfor = ['Qtr 01 \\(Jan-Mar\\) 2012','Qtr 02 \\(Apr-Jun\\) 2012', 'Qtr 03 \\(Jul-Sept\\) 2012','Qtr 04 \\(Oct-Dec\\) 2018']\n",
    "collections = collections[~collections.index.str.contains('|'.join(searchfor))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Read Workload Data\n",
    "workload = pd.read_excel(os.path.join('Source Emails & Source Files','Files','Workload',\n",
    "                                      'COBRA_Air','fy13-18 stats by_Month National.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only Comm Aircraft Pax/Crew Combined (ECAR) Workload metric from PPAE file\n",
    "workload = workload.iloc[13,:]\n",
    "# Remove unnecessary and non-numeric columns\n",
    "workload = workload[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn Series into a dataframe. Rename the first column \"Workload\"\n",
    "workload = workload.to_frame()\n",
    "workload.columns = ['Workload']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Calendar Year and Month Columns\n",
    "workload['Month'] = workload.index.str.split('/').str[0]\n",
    "workload['Calendar Year'] = workload.index.str.split('/').str[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter on years not a part of analysis\n",
    "years = ['2012','2013','2014','2015','2016','2017','2018']\n",
    "workload = workload[workload['Calendar Year'].isin(years)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build out Remittance Period Columns\n",
    "conditions = [(workload['Month'] == '1'), (workload['Month'] == '2'), (workload['Month'] == '3'), \n",
    "              (workload['Month'] == '4'), (workload['Month'] == '5'), (workload['Month'] == '6'),\n",
    "              (workload['Month'] == '7'),(workload['Month'] == '8'),(workload['Month'] == '9'),\n",
    "              (workload['Month'] == '10'),(workload['Month'] == '11'),(workload['Month'] == '12')] \n",
    "choices = ['Qtr 01 (Jan-Mar)','Qtr 01 (Jan-Mar)','Qtr 01 (Jan-Mar)',\n",
    "           'Qtr 02 (Apr-Jun)','Qtr 02 (Apr-Jun)','Qtr 02 (Apr-Jun)',\n",
    "           'Qtr 03 (Jul-Sept)','Qtr 03 (Jul-Sept)', 'Qtr 03 (Jul-Sept)',\n",
    "           'Qtr 04 (Oct-Dec)','Qtr 04 (Oct-Dec)','Qtr 04 (Oct-Dec)']\n",
    "workload['Remittance Period'] = np.select(conditions, choices, default='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to Remittance Period plus Calendar Year to merge with Collection data\n",
    "workload.index = workload['Remittance Period'] + ' ' + workload['Calendar Year']\n",
    "# Drop unnecssary columns\n",
    "workload.drop(['Calendar Year', 'Month','Remittance Period'], inplace = True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum on Remittance Period\n",
    "workload = workload.groupby(workload.index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "workload['Remittance Period'] = workload.index.str.split('\\)').str[0] + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(workload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/1/2018     2018 \n",
      "8/1/2018     2018 \n",
      "7/1/2018     2018 \n",
      "6/1/2018     2018 \n",
      "5/1/2018     2018 \n",
      "             ...  \n",
      "2/1/2009     2009 \n",
      "1/1/2009     2009 \n",
      "12/1/2008    2008 \n",
      "11/1/2008    2008 \n",
      "10/1/2008    2008 \n",
      "Name: Calendar Year, Length: 120, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Clean Workload Df\n",
    "#remove cruise data\n",
    "workload = workload.iloc[0:6,:]\n",
    "#select data we want to work with\n",
    "workload2 = workload.iloc[::2,:2]\n",
    "workload3 = workload.iloc[[1,3,5],2:]\n",
    "#reset indices for merge\n",
    "workload2.reset_index(drop = True, inplace = True)\n",
    "workload3.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# concat dataframes to get cleaned workload df\n",
    "workload = pd.concat([workload2, workload3], axis=1, sort=False)\n",
    "#sum Data Element and Workload ID columns into one descriptor\n",
    "workload['Workload Element'] = workload.iloc[:,0]+': '+workload.iloc[:,1]\n",
    "workload = workload.iloc[:,::-1]\n",
    "workload = workload.iloc[:,:-2]\n",
    "#%%\n",
    "workload = workload.transpose()\n",
    "#promote first row to column headers and drop first row\n",
    "workload.columns = workload.iloc[0]\n",
    "workload = workload.iloc[1:]\n",
    "\n",
    "# Create Calendar Year and Month Columns\n",
    "workload['Month'] = workload.index.str.split('/').str[0]\n",
    "workload['Calendar Year'] = workload.index.str.split('/').str[2] + \" \"\n",
    "print(workload['Calendar Year'])\n",
    "# Filter on years not a part of analysis\n",
    "years = ['2012 ','2013 ','2014 ','2015 ','2016 ','2017 ','2018 ']\n",
    "workload = workload[workload['Calendar Year'].isin(years)]\n",
    "\n",
    "#%%\n",
    "# Build out Remittance Period Columns\n",
    "conditions = [(workload['Month'] == '1'), (workload['Month'] == '2'), (workload['Month'] == '3'), (workload['Month'] == '4'), (workload['Month'] == '5'), (workload['Month'] == '6'),(workload['Month'] == '7'),(workload['Month'] == '8'),(workload['Month'] == '9'),(workload['Month'] == '10'),(workload['Month'] == '11'),(workload['Month'] == '12')] \n",
    "choices = ['Qtr 01 (Jan-Mar)','Qtr 01 (Jan-Mar)','Qtr 01 (Jan-Mar)','Qtr 02 (Apr-Jun)','Qtr 02 (Apr-Jun)','Qtr 02 (Apr-Jun)','Qtr 03a (Jul-Aug)','Qtr 03a (Jul-Aug)', 'Qtr 03b (Sept)','Qtr 04 (Oct-Dec)','Qtr 04 (Oct-Dec)','Qtr 04 (Oct-Dec)']\n",
    "workload['Period'] = np.select(conditions, choices, default='error')\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "# Match Period Column to Collections\n",
    "workload['Period'] = workload['Period'] + ' ' + workload['Calendar Year']\n",
    "# Set index to Remittance Period\n",
    "workload = workload.set_index('Period')\n",
    "# drop unnecssary columns\n",
    "workload = workload.drop(['Calendar Year','Month'], axis = 1)\n",
    "# Sum on Remittance Period\n",
    "workload = workload.groupby(workload.index).sum()\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "#remove non FY2013-2018 data\n",
    "#workload = workload.iloc[1:,:]\n",
    "#collections_475 = collections_475.iloc[1:-1,:]\n",
    "\n",
    "#%%\n",
    "#remove non FY2013-2018 data\n",
    "#searchfor = ['Qtr 02 \\(Apr-Jun\\) 2012', 'Qtr 03a \\(Jul-Aug\\) 2012','Qtr 03b \\(Sept\\) 2012']\n",
    "#collections_475 = collections_475[~collections_475.index.str.contains('|'.join(searchfor))]\n",
    "#workload = workload[~workload.index.str.contains('|'.join(searchfor))]\n",
    "\n",
    "#Add sum of workload columns\n",
    "workload['Workload'] = workload.sum(axis = 1)\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workload_collections = pd.merge(workload,collections,how = 'inner', left_index = True, right_index = True)\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
